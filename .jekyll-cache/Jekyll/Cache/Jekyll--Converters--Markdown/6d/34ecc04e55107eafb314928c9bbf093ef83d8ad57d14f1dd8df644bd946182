I"ip<h3 id="design-your-first-custom-neural-network-from-scratch-using-pytorch">Design your First Custom Neural Network from scratch Using PyTorch</h3>

<p><em>Okay, hereâ€™s an original one : 
So, they ran a deep neural network to predict the hottest technological trend of 2014. Surprisingly, it predicted the answer to be deep neural networks! People accused it was biased. NN coders assumed it was probably due to the large initial bias.</em>ðŸ˜…</p>

<p>To jump directly to <a href="https://github.com/Prudhvi0001/MNIST/blob/master/MNIST_Pytorch.ipynb">code</a>.</p>

<p><a href="https://github.com/Prudhvi0001/Data-science-best-resources">Here is a link for more best resources to learn Data Science.</a></p>

<p>If you already used TenserFlow or keras to create Neural Network architecture this is gonna be a cake walk for you. Although TenserFlow is great for creating models it doesnâ€™tâ€™t support GPU as efficiently as PyTorch.</p>

<blockquote>
  <p>The main purpose of PyTorch is to replace numpy with tensors which support GPU computation and unlike keras it provides maximum flexibility to customize to Network architecture.</p>
</blockquote>

<p>Letâ€™s not waste time and get started.!</p>

<p>Install PyTorch: Copy the command in this link and run in your terminal based on your system requirements <a href="https://pytorch.org/get-started/locally/">Link</a>.</p>

<p><strong>Import Libraries:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span> <span class="c1"># Contains Required functions and layers
</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span> <span class="c1"># For neural network functions:
</span>
<span class="c1"># For Open ML datasets available in PyTorch.
</span><span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>

<span class="c1"># Contains Optimization function available in PyTorch.
</span><span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="n">optim</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Letâ€™s try to build a 4 layer network with hello world data set of machine learning. <a href="http://yann.lecun.com/exdb/mnist/">MNIST</a></p>

<p>Import Dataset: MNIST Hand Written Digits</p>

<p>The data consists of a series of images (containing hand-written numbers) that are of the size <code class="language-plaintext highlighter-rouge">28 X 28</code>. We will discuss the images shortly, but our plan is to load the data into batches of <code class="language-plaintext highlighter-rouge">64</code><strong>*.*</strong></p>

<p>PyTorch datasets library has all the popular datasets required to get you started.(<a href="https://pytorch.org/docs/stable/torchvision/datasets.html">Available Datasets</a>)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre></td><td class="rouge-code"><pre><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="p">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                                <span class="n">transforms</span><span class="p">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,)),</span>
                              <span class="p">])</span>
<span class="n">trainset</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s">'~/.pytorch/MNIST_data/'</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

<span class="c1"># trainloader is what holds the data loader object which takes care of shuffling the data and constructing the batches
</span><span class="n">trainloader</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">trainset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">testset</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s">'~/.pytorch/MNIST_data/'</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

<span class="n">testloader</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">testset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="c1"># No need to shuffle test data.
</span></pre></td></tr></tbody></table></code></pre></div></div>

<p>Transform function above normalizes data to mean =0.5 and SD = 0.5</p>

<p>Load both train and test with same batch size(It doesnâ€™t need to be <strong>64</strong>). each iteration of data gives 64 images and their labels.</p>

<p>Basic steps of neural network contains :</p>

<blockquote>
  <p><strong>Forward Pass</strong> -&gt; <strong>Loss calculation</strong> -&gt; <strong>Backward Pass to optimize weights</strong></p>
</blockquote>

<p><strong>Forward Pass:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
</pre></td><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">CustomNeuralNetwork</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>

        <span class="c1"># Define Layers:
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span> <span class="c1"># layer 1
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">l2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span> <span class="c1"># layer 2
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">l3</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span> <span class="c1"># layer 3
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">l4</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span> <span class="c1"># layer 4
</span>
        <span class="c1"># Define Activation functions:
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sigmoid</span><span class="p">()</span> 
        <span class="bp">self</span><span class="p">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">softmax</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">LogSoftmax</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> 


    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="s">"""
        Layers: 4
        Activation Functions:
        RELU for first two layers
        Sigmoid for third layer
        Log Softmax for last layer
        """</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">l2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">l3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">l4</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>

    
<span class="n">NN</span> <span class="o">=</span> <span class="n">CustomNeuralNetwork</span><span class="p">()</span>  <span class="c1"># Intialize you NN
</span></pre></td></tr></tbody></table></code></pre></div></div>

<p>The nn.Module allows to override and create your own network architectures. You can even explore further by creating your own weights, bias and backward pass etc.</p>

<p><strong>Loss Calculation:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">NLLLoss</span><span class="p">()</span> <span class="c1"># Initialize loss function
</span></pre></td></tr></tbody></table></code></pre></div></div>

<p>Here I am using Negative log likelihood Loss. As our Data is a multi-class problem with Log Soft-max activation. <a href="https://pytorch.org/docs/stable/nn.html#non-linear-activations-other">ReadHere</a></p>

<p><strong>Optimizer:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">NN</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Adam optimization is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments. <a href="https://pytorch.org/docs/stable/optim.html">ReadHere</a></p>

<p><strong>Train The Model (Back Propagation to update Weights):</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre></td><td class="rouge-code"><pre><span class="c1"># No:of times to train data
</span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">5</span>
<span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">trainloader</span><span class="p">:</span>
        <span class="c1"># Faltten the images 
</span>        <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">images</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># set optimizer gradients to zero:
</span>        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>

        
        <span class="n">output</span> <span class="o">=</span> <span class="n">NN</span><span class="p">(</span><span class="n">images</span><span class="p">)</span> <span class="c1"># Intial output
</span>        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="c1"># Loss  Caluclation
</span>        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span> <span class="c1"># Pass loss function gradients to pervious layers:
</span>        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span> <span class="c1"># Update Weights
</span>
    <span class="k">print</span><span class="p">(</span><span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">())</span> <span class="c1"># print loss for each epoch
</span></pre></td></tr></tbody></table></code></pre></div></div>

<p>Sample Output:</p>

<p>0.047625500708818436
0.0713285580277443
0.018748214468359947
0.023736275732517242
0.032160669565200806</p>

<p>Observe that for each epoch The loss reduces (<strong>*Donâ€™t forget to set optimizers to zero_grad() before initialization.*</strong>)</p>

<p>Best Practice would be save your model for further use so that you need to train again: Using PyTorch you can save either model or state_dict() which requires less space.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="c1"># Save your model
</span><span class="n">PATH</span> <span class="o">=</span> <span class="s">'./NeuralNet.pth'</span>
<span class="n">torch</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="n">NN</span><span class="p">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH</span><span class="p">)</span> 
<span class="c1"># Load your model 
</span><span class="n">NN</span> <span class="o">=</span> <span class="n">CustomNeuralNetwork</span><span class="p">()</span>
<span class="n">NN</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">))</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>Predict on Test Data:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre></td><td class="rouge-code"><pre><span class="c1"># Accuracy on Test Data
</span><span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">testloader</span><span class="p">:</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">images</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">NN</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">output</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">).</span><span class="nb">sum</span><span class="p">().</span><span class="n">item</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Accuracy of the network on the 10000 test images: %d %%'</span> <span class="o">%</span> <span class="p">(</span>
    <span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span><span class="p">))</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Sample Output:</p>

<p>Accuracy of the network on the 10000 test images: 97 %</p>

<p><strong>Accuracy of each label:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre></td><td class="rouge-code"><pre><span class="n">classes</span> <span class="o">=</span> <span class="p">(</span><span class="s">'0'</span><span class="p">,</span><span class="s">'1'</span><span class="p">,</span><span class="s">'2'</span><span class="p">,</span><span class="s">'3'</span><span class="p">,</span><span class="s">'4'</span><span class="p">,</span><span class="s">'5'</span><span class="p">,</span><span class="s">'6'</span><span class="p">,</span><span class="s">'7'</span><span class="p">,</span><span class="s">'8'</span><span class="p">,</span><span class="s">'9'</span><span class="p">)</span>
<span class="n">class_correct</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="mf">0.</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="n">class_total</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="mf">0.</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">testloader</span><span class="p">:</span>
        <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">images</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">NN</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">c</span> <span class="o">=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">).</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
            <span class="n">label</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">class_correct</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">+=</span> <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">item</span><span class="p">()</span>
            <span class="n">class_total</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="c1"># Accuracy of each class:
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Accuracy of %5s : %2d %%'</span> <span class="o">%</span> <span class="p">(</span>
        <span class="n">classes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">class_correct</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="n">class_total</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Sample Output:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre></td><td class="rouge-code"><pre><span class="n">Accuracy</span> <span class="n">of</span>     <span class="mi">0</span> <span class="p">:</span> <span class="mi">100</span> <span class="o">%</span>
<span class="n">Accuracy</span> <span class="n">of</span>     <span class="mi">1</span> <span class="p">:</span> <span class="mi">100</span> <span class="o">%</span>
<span class="n">Accuracy</span> <span class="n">of</span>     <span class="mi">2</span> <span class="p">:</span> <span class="mi">92</span> <span class="o">%</span>
<span class="n">Accuracy</span> <span class="n">of</span>     <span class="mi">3</span> <span class="p">:</span> <span class="mi">98</span> <span class="o">%</span>
<span class="n">Accuracy</span> <span class="n">of</span>     <span class="mi">4</span> <span class="p">:</span> <span class="mi">98</span> <span class="o">%</span>
<span class="n">Accuracy</span> <span class="n">of</span>     <span class="mi">5</span> <span class="p">:</span> <span class="mi">90</span> <span class="o">%</span>
<span class="n">Accuracy</span> <span class="n">of</span>     <span class="mi">6</span> <span class="p">:</span> <span class="mi">96</span> <span class="o">%</span>
<span class="n">Accuracy</span> <span class="n">of</span>     <span class="mi">7</span> <span class="p">:</span> <span class="mi">98</span> <span class="o">%</span>
<span class="n">Accuracy</span> <span class="n">of</span>     <span class="mi">8</span> <span class="p">:</span> <span class="mi">98</span> <span class="o">%</span>
<span class="n">Accuracy</span> <span class="n">of</span>     <span class="mi">9</span> <span class="p">:</span> <span class="mi">96</span> <span class="o">%</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>We can observe that the model is confusing for 2 and 5, A simple solution would be collect more data of 2â€™s and 5â€™s or you explore options like Data Augmentation, Shift images to center before passing it train your model.</p>

<p>For More Advanced Practice refer <a href="https://medium.com/dair-ai/pytorch-1-2-introduction-guide-f6fa9bb7597c">Elvis</a>.</p>

<p>If you are still struck at making a decision to learn tensorflow or pytorch like me at the start. <a href="https://towardsdatascience.com/tensorflow-vs-pytorch-the-battle-continues-9dcd34bb47d4">ReadThis</a>.</p>
:ET